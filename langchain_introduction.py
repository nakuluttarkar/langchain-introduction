# -*- coding: utf-8 -*-
"""langchain-introduction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11FGsqhayQ1vN6LOth-UU2mIoH1LF7-GG
"""

!pip install -qU \
  langchain-core==0.3.33 \
  langchain-openai==0.3.3 \
  langchain-community==0.3.16 \
  numpy==1.26.4

import os
from getpass import getpass

os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY") or getpass(
    "Enter OpenAI API Key: "
)

openai_model = "gpt-5-nano"

from langchain_openai import ChatOpenAI
from langchain_core.caches import InMemoryCache, BaseCache # Import BaseCache
from langchain_core.globals import set_llm_cache
from langchain_core.callbacks import Callbacks # Import Callbacks

set_llm_cache(InMemoryCache())
ChatOpenAI.model_rebuild()

# For normal accurate responses
llm = ChatOpenAI(temperature=0.0, model=openai_model)

# For unique creative responses
creative_llm = ChatOpenAI(model=openai_model)

article = """
\
We believe AI's short—to mid-term future belongs to agents and that the long-term future of *AGI* may evolve from agentic systems. Our definition of agents covers any neuro-symbolic system in which we merge neural AI (such as an LLM) with semi-traditional software.

With agents, we allow LLMs to integrate with code — allowing AI to search the web, perform math, and essentially integrate into anything we can build with code. It should be clear the scope of use cases is phenomenal where AI can integrate with the broader world of software.

In this introduction to AI agents, we will cover the essential concepts that make them what they are and why that will make them the core of real-world AI in the years to come.

---

## Neuro-Symbolic Systems

Neuro-symbolic systems consist of both neural and symbolic computation, where:

- Neural refers to LLMs, embedding models, or other neural network-based models.
- Symbolic refers to logic containing symbolic logic, such as code.

Both neural and symbolic AI originate from the early philosophical approaches to AI: connectionism (now neural) and symbolism. Symbolic AI is the more traditional AI. Diehard symbolists believed they could achieve true AGI via written rules, ontologies, and other logical functions.

The other camp were the connectionists. Connectionism emerged in 1943 with a theoretical neural circuit but truly kicked off with Rosenblatt's perceptron paper in 1958 [1][2]. Both of these approaches to AI are fascinating but deserve more time than we can give them here, so we will leave further exploration of these concepts for a future chapter.

Most important to us is understanding where symbolic logic outperforms neural-based compute and vice-versa.

| Neural | Symbolic |
| --- | --- |
| Flexible, learned logic that can cover a huge range of potential scenarios. | Mostly hand-written rules which can be very granular and fine-tuned but hard to scale. |
| Hard to interpret why a neural system does what it does. Very difficult or even impossible to predict behavior. | Rules are written and can be understood. When unsure why a particular ouput was produced we can look at the rules / logic to understand. |
| Requires huge amount of data and compute to train state-of-the-art neural models, making it hard to add new abilities or update with new information. | Code is relatively cheap to write, it can be updated with new features easily, and latest information can often be added often instantaneously. |
| When trained on broad datasets can often lack performance when exposed to unique scenarios that are not well represented in the training data. | Easily customized to unique scenarios. |
| Struggles with complex computations such as mathematical operations. | Perform complex computations very quickly and accurately. |

Pure neural architectures struggle with many seemingly simple tasks. For example, an LLM *cannot* provide an accurate answer if we ask it for today's date.

Retrieval Augmented Generation (RAG) is commonly used to provide LLMs with up-to-date knowledge on a particular subject or access to proprietary knowledge.

## Not only LLMs and Tool Calls

LLMs paired with tool calling are powerful but far from the only approach to building agents. Using the definition of neuro-symbolic, we cover architectures such as:

- Multi-agent workflows that involve multiple LLM-tool (or other agent structure) combinations.
- More deterministic workflows where we may have set neural model-tool paths that may fork or merge as the use case requires.
- Embedding models that can detect user intents and decide tool-use or LLM selection-based selection in vector space.

These are just a few high-level examples of alternative agent structures. Far from being designed for niche use cases, we find these alternative options to frequently perform better than the more common ReAct or Tool agents. We will cover all of these examples and more in future chapters.

Agents are fundamental to the future of AI, but that doesn't mean we should expect that future to come from agents in their most popular form today. ReAct and Tool agents are great and handle many simple use cases well, but the scope of agents is much broader, and we believe thinking beyond ReAct and Tools is key to building future AI.

You can sign up for the [Aurelio AI newsletter](https://b0fcw9ec53w.typeform.com/to/w2BDHVK7) to stay updated on future releases in our comprehensive course on agents.
"""

from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate

system_prompt = SystemMessagePromptTemplate.from_template(
    "you are an AI assistant named: {name} that helps to generate titles for Articles", input_variables=["name"]
)

user_prompt = HumanMessagePromptTemplate.from_template(
    """You are tasked with creating a name for the article. The article is here for you to examine
    -----
    {article}
    -----

    The name should be based on the context of the article.
    Make it creative, catchy and clear.

    Only output the article name, no other explaination or text should be given""", input_variables=["article"]
)

user_prompt.format(article="test").content

first_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])

first_prompt.format_messages(article="article", name = "jarvis")

chain_one = (
    {"article": lambda x: x["article"], "name": lambda x: x["name"]}
    | first_prompt
    | creative_llm
    | {"article_title": lambda x: x.content}
)

article_title = chain_one.invoke({"article": article, "name": "jarvis"})
article_title

second_user_prompt = HumanMessagePromptTemplate.from_template(
    """You are tasked to generate description for an article. The article is here for you to examine:
    ----
    ###Title: {article_title}

    {article}

    ----
    Give the SEO friendly article description
    Make sure to keep it within 200 characters.
    Do not output anything other than the description.

    """, input = ["article_title", "article"]
)

second_prompt = ChatPromptTemplate.from_messages([second_user_prompt])

second_prompt

chain_two = (
    {"article_title": lambda x: x["article_title"], "article": lambda x: x["article"]}
    | second_prompt
    | creative_llm
    | {"article_description": lambda x: x.content}
)

article_description = chain_two.invoke({"article_title": article_title["article_title"], "article": article})
article_description

third_user_prompt = HumanMessagePromptTemplate.from_template(
    """
    You are tasked with creating a new paragraph for the article. This is the article:

    ---

    {article}

    ---

    Choose one paragraph to review and edit. During your edit
    ensure you provide constructive feedback to the user so they
    can learn where to improve their own writing.

    """, input_variables=["article"]
)

third_prompt = ChatPromptTemplate.from_messages([third_user_prompt])

from pydantic import BaseModel, Field

class Paragraph(BaseModel):
  original_paragraph: str = Field(description="The original paragraph")
  edited_paragraph: str = Field(description="The improved edited paragraph")
  feedback: str = Field(description="Constructive Feedback for the original paragraph")

structured_llm = creative_llm.with_structured_output(Paragraph)

chain_three = (
    {"article": lambda x: x["article"]}
    | third_prompt
    | structured_llm
    | {
        "original_paragraph": lambda x: x.original_paragraph,
        "edited_paragraph": lambda x: x.edited_paragraph,
        "feedback": lambda x: x.feedback
    }
)

output = chain_three.invoke({"article": article})
output

